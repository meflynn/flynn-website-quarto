{
  "hash": "125ad9028b9aeac142bd80626330f574",
  "result": {
    "markdown": "---\ntitle: Hurdle lognormal distribution densities?\nauthor: Michael Flynn\ndate: '2021-03-03'\nslug: []\ncategories:\n  - Blogging\n  - stats\ntags:\n  - blogging\n  - stats\n---\n\n\n\n\nAs a part of a larger project I've been working with BRMS and some models and family functions that are new to me. In particular, my work on troop deployments has made me think more about hurdle models. I've had some experience with zero-inflated models in the past, but haven't spent a lot of time with hurdle models, specifically. Anyway, without going down the rabbit hole, I've been thinking about how to create probability density functions for some of these models. The `{countreg}` package contains some functions for hurdle negative binomial models, which got me thinking about building something similar for hurdle lognormal distributions. I'm really operating one the frontiers of my own experience/abilities, so I may be way off here, but let's give this a shot and see if it works.\n\n# Background\n\nI work a lot with military deployment data. Typically these are country-year observations of the number of US military personnel stationed in various overseas locations (think Germany, Japan, etc.). So far most of our work has treated deployments as a predictor variable, but more recently we've started thinking more about modeling deployment levels themselves. In general, there tends to be a ton of skew in these data. For example, from 1990 forward the troop deployment data we have are more or less distributed like this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n\n# Simulation . Values reflect what we see in our data.\nsims <- 1e4\nmuval = 2.8\nsdval = 2.54\npival = 0.2\n\n\nsimvals <- rep(NA, sims)\nsimvals[c(1:2000)] <- rep(0, sims*0.2)\nsimvals[c(2001:10000)] <- rlnorm(sims*0.8, meanlog = muval, sdlog = sdval)\n\n\nhist(log1p(simvals), breaks = 200, main = \"Distribution of Simulated Troop Data\")\n```\n\n::: {.cell-output-display}\n![](hurdle-lognormal-densities_files/figure-html/simulated-data-fig-1.png){fig-align='center' width=75%}\n:::\n:::\n\n\nWe've got about 20% zero values, and the non-zero values have a median of 16 and a mean of about 1,700. Conceivably every country *could* receive deployments, but some are highly unlikely to (e.g. North Korea). But even countries that do host US personnel tend to host very small deployments, as you can see by the relatively small median value. The mean is dragged upwards by large, long-standing legacy deployments in places like Germany, Japan, and South Korea. \n\n# Problem\n\nI'm glossing over a lot of the details here, but working on this has prompted me to think more about using hurdle models (like I already said). Yada yada yada, this has led me to think about what a probability density function for a hurdle model looks like. The `{stats}` package in `R` comes with a set of functions for handling lognormal distributions, but doesn't appear to have anything to handle hurdle variants. Riffing off of the aforementioned `{countreg}` package, this is my attempt to create something comparable for hurdle lognormal distributions (I couldn't find one with Elaine).\n\n<div class=\"tenor-gif-embed\" data-postid=\"5569195\" data-share-method=\"host\" data-width=\"100%\" data-aspect-ratio=\"1.4821428571428572\"><a href=\"https://tenor.com/view/seinfeld-jason-alexander-george-costanza-yada-yada-yada-pissed-gif-5569195\">Seinfeld Jason Alexander GIF</a> from <a href=\"https://tenor.com/search/seinfeld-gifs\">Seinfeld GIFs</a></div><script type=\"text/javascript\" async src=\"https://tenor.com/embed.js\"></script>\n\n\n# Maybe a working probability density function?\n\nThis is my shot at creating a probability density function...umm...function. I started with the builtin `dlnorm()` function, but the problem is that it only accepts positive values. If we have a lot of data that are failing to cross that hurdle (i.e. 0 values) then this doesn't really work. I think the solution is to insert an argument that details the propotion/probability of 0 values in the data (i.e. the `pval` argument). For non-zero values we have to first get the probability using `dlnorm()`. Once we generate the probability value for the `x` value using `dlnorm()` we then have to weight that probability value by the proportion of non-zero values in the data. In this case we enter a `pval` argument of 0.2 since 20% of the data are 0s, but when we calculate the probability for some values > 0 we want to make sure that's weighted by 0.8 since 80% of observations are >  0. So really this is $1 - pval$. If `x` equals zero then the probability should (I think?) just default to the `pval` argument.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n\ndhlnorm <- function(x, meanlog, sdlog, pval) {\n  \n    if (x > 0) {\n    \n    value <- dlnorm(x, meanlog = meanlog, sdlog = sdlog, log = FALSE) * (1-pval)\n    \n    return(value)\n    \n  } else {\n    \n    value <- pval\n    \n    return(value)\n  }\n  }\n\n\nprob <- dhlnorm(3, meanlog = muval, sdlog = sdval, pval = 0.2)\n\nprint(prob)\n## [1] 0.03346686\n```\n:::\n\n\nAgain, this is very much on the frontiers of my experience, so if anyone has any feedback I'd appreciate it. I have some potential applications in mind, so this is more than just running down a rabbit hole. I promise.\n\n\n",
    "supporting": [
      "hurdle-lognormal-densities_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}